---
layout: post
use_math: true
title: "[Knowledge Tracing] Dynamic Key-Value Memory Networks for Knowledge Tracing 논문 정리"
date: 2021-04-17 00:00:00
tagline: "메모리 네트워크를 활용하여 DKT 모델에 해석 가능성을 부여하고 성능도 향상시킨 DKVMN 논문을 스터디하여 정리"
categories:
- Paper Review
tags:
- knowledge tracing
- deep learning
- recommender system
image: /thumbnail-mobile.png
author: "Hyungcheol Noh"
permalink: /2021-04-17-dkvmn
---

이번 포스팅은 다음의 논문을 스터디하여 정리하였다:
- [링크1](https://arxiv.org/pdf/1611.08108.pdf)

## Knowledge Tracing
Knowledge Tracing이란 주어진 문제들을 풀어가는 사용자의 수준을 파악하기 위한 학습 모델을 추정하기 위한 태스크를 말한다. 기존 고전 방법론으로는 Bayesian Network 및 확률 모델 파라미터 추정 방법론들을 활용한 Bayesian Knowledge Tracing (BKT)을 중심으로 연구가 되어왔으며, 현재는 딥러닝 기술을 활용하여 Deep Knowledge Tracing (DKT)을 중심으로 다양한 모델들에 대한 연구가 수행되고 있다.

이번 포스트에서 소개하고자 하는 논문은 딥러닝 기반의 Knowledge Tracing 모델이며 Dynamic Key-Value Memory Network (DKVMN)라고 불리우는 모델이다. 논문에서는 DKVMN의 우수성을 강조하기 위하여 추가적으로 Memory-Augmented Neural Network (MANN)도 제시하였지만 이번 포스트에서는 DKVMN만을 설명하도록 하겠다. (추후 MANN에 대한 설명을 추가할 예정)

또한 Knowledge Tracing에 대한 전반적인 문제 정의에 대해서는 [링크](https://hcnoh.github.io/2019-06-14-deep-knowledge-tracing)를 참고하면 도움이 될 것이다.

## 문제 정의
DKVMN은 Knowledge Tracing 연구에서 (필자가 알기로는) 최초로 다양한 개념이 존재하고 그 개념들 사이에 상호작용을 통해서 사용자의 학습 활동이 수행된다는 점을 주장하였다. DKVMN에서 제시한 문제 세팅을 간단히 요약하면 아래의 그림과 같다.

![](/assets/img/2021-04-17-dkvmn/2021-04-17-dkvmn_2021-04-17-15-36-03.png)

즉, BKT는 사용자와 개념들 각각마다 확률 모델을 가정하고 현상을 설명하기위한 최적의 파라미터를 추정하려고 시도한다.

DKT는 개념을 따로 가정하지는 않고 사용자에 따라 반응을 예측하는 딥러닝 모델을 활용하였고 개념은 딥러닝 상에서 숨겨진 Black Box로만 존재하여 우리가 확인할 수 없다.

하지만 DKVMN은 기존의 모델들과는 다르게 다양한 개념들이 존재하고 이들 사이에는 서로 상호작용이 가능하며 그를 통해서 사용자의 반응을 추정하는 모델을 제시한다.

여기서 중요한 점은 개념을 가정했다는 것보다도 다양한 개념들 사이의 상호작용을 상정하고 모델을 구축했다는 점을 들 수 있을것 같다.

## 모델 구조
![](/assets/img/2021-04-17-dkvmn/2021-04-17-dkvmn_2021-04-17-15-44-28.png)

DKVMN의 모델 구조는 MANN 모델 구조에서 External Memory Matrix를 Value Matrix $$\mathbf{M}_t^v$$ 및 Key Matrix $$\mathbf{M}^k$$로 나누는 방식으로 구현하였다.

Value Matrix $$\mathbf{M}^v_t$$는 $$d_v\times N$$의 크기를 가지고 있으며 $$N$$개의 Latent Concept들 $$\{ c^1, c^2, \cdots, c^N \}$$ 각각에 대한 사용자의 Concept States $$\{ \mathbf{s}_t^1, \mathbf{s}_t^2, \cdots, \mathbf{s}_t^N \}$$을 인코딩하고 있다. 밑첨자 $$t$$가 들어있는 이유는 모델의 추론 과정에서 이 메모리 값들은 시간에 따라서 동적으로(Dynamic) 변화한다는 의미이며 이것이 DKVMN의 이름을 가지게 된 이유라고 볼 수 있다.

반면 Key Matrix $$\mathbf{M}^k$$는 $$N$$개의 Latent Concept들 $$\{ c^1, c^2, \cdots, c^N \}$$을 인코딩하고 있는 행렬이며 모델의 추론 과정에서 시간과 관계없이 변하지않는 Static한 메모리라고 볼 수 있다.

## 기타 참고 자료
- PyTorch로 구현한 Deep Knowledge Tracing (by Hyungcheol Noh): [Knowledge Tracing Collection with PyTorch](https://github.com/hcnoh/knowledge-tracing-collection-pytorch)
- [Deep Knowledge Tracing 논문 정리](https://hcnoh.github.io/2019-06-14-deep-knowledge-tracing)

## 수정 사항
- 2021.04.17
    - 최초 게시 (현재 작성 진행중)