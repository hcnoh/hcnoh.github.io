---
layout: post
use_math: true
title: "[비전-언어 모델] 2. Vision Transformer"
date: 2024-01-17 00:00:00
tagline: "비전-언어 모델에서 이미지 및 비디오 인코더로 주로 활용되는 Transformer 모델인 Vision Transformer에 대한 소개"
categories:
- 비전-언어 모델 스터디
tags:
- deep learning
- natural language processing
- computer vision
- vision-language models
image: /thumbnail-mobile.png
author: "Hyungcheol Noh"
permalink: /2024-01-17-vlm-02
---

이번 포스트에서는 비전-언어 모델에서 이미지 또는 비디오를 인코딩하기 위해서 주로 활용되는 모델인 `Vision Transformer`에 대해서 설명한다. `Transformer` 모델은 [링크](https://hcnoh.github.io/2023-02-25-nlp-03)에서 자세히 확인할 수 있듯이 자연어 처리 분야에서 처음으로 활용되었다. Transformer의 가치는 `Self-Attention 메커니즘`에서 

## 목차
- [정리](#정리)
- [참고 자료](#참고-자료)
- [수정 사항](#수정-사항)

## 정리

## 참고 자료
- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)

## 수정 사항
- 2024.01.12
    - 최초 게제